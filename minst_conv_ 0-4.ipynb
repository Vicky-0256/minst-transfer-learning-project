{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我卷卷卷\n",
    "\n",
    "在这节课中，我们学习了如何使用torchvision加载图像库，如何构建一个简单的卷积神经网络，并了解如何训练这个卷积神经网络\n",
    "之后，我们还学会了如何对训练好的卷积网络进行分析\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第III课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需要的包，请保证torchvision已经在你的环境中安装好.\n",
    "# 在Windows需要单独安装torchvision包，在命令行运行pip install torchvision即可\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 首先，我们需要学习PyTorch自带的数据加载器，包括dataset，sampler，以及data loader这三个对象组成的套件。\n",
    "2. 当数据集很小，格式比较规则的时候，数据加载三套件的优势并不明显。但是当数据格式比较特殊，以及数据规模很大（内存无法同时加载所有数据）\n",
    "的时候，特别是，我们需要用不同的处理器来加载数据的时候，三套件的威力就会显现出来了。它会将数据加载、分布的任务自动完成。\n",
    "3. 在使用的时候，我们用dataset来装载数据集，用sampler来采样数据集。而对数据集的迭代、循环则主要通过data_loader来完成。\n",
    "4. 创建一个data_loader就需要一个dataset和一个datasampler，它基本实现的就是利用sampler自动从dataset种采样\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第III课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置图像读取器的超参数\n",
    "image_size = 28  #图像的总尺寸28*28\n",
    "batch_size = 64  #批处理的尺寸大小\n",
    "\n",
    "# 如果系统中存在着GPU，我们将用GPU来完成张量的计算\n",
    "use_cuda = torch.cuda.is_available() #定义一个布尔型变量，标志当前的GPU是否可用\n",
    "\n",
    "# 如果当前GPU可用，则将优先在GPU上进行张量计算\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "itype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "\n",
    "# 加载MINIST数据，如果没有下载过，就会在当前路径下新建/data子目录，并把文件存放其中\n",
    "# MNIST数据是属于torchvision包自带的数据，所以可以直接调用。\n",
    "# 在调用自己的数据的时候，我们可以用torchvision.datasets.ImageFolder或者torch.utils.data.TensorDataset来加载\n",
    "\n",
    "#定义一个数据输入函数，min为最小值，max为最大值\n",
    "def dataset(min,max):\n",
    "    train_dataset = dsets.MNIST(root='./data',  #文件存放路径\n",
    "                            train=True,   #提取训练集\n",
    "                            transform=transforms.ToTensor(),  #将图像转化为Tensor\n",
    "                            download=True)\n",
    "\n",
    "     # 加载测试数据集\n",
    "    test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "    tr=((train_dataset.targets <=max)&(train_dataset.targets >=min)).nonzero().squeeze()\n",
    "    train_dataset.targets=train_dataset.targets[tr]\n",
    "    train_dataset.data=train_dataset.data[tr]\n",
    "    \n",
    "    te=((test_dataset.targets <=max)&(test_dataset.targets >=min)).nonzero().squeeze()\n",
    "    test_dataset.targets=test_dataset.targets[te]\n",
    "    test_dataset.data=test_dataset.data[te]\n",
    "    #print(train_dataset)\n",
    "    #print(test_dataset)\n",
    "    \n",
    "    \n",
    "    # 训练数据集的加载器，自动将数据分割成batch，顺序随机打乱\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "     \n",
    "\n",
    "     # 首先，我们定义下标数组indices，它相当于对所有test_dataset中数据的编码\n",
    "     # 然后定义下标indices_val来表示校验集数据的那些下标，indices_test表示测试集的下标\n",
    "    lens=len(test_dataset)\n",
    "    indices = range(lens)\n",
    "    indices_val = indices[:int(lens/2)]\n",
    "    indices_test = indices[int(lens/2):]\n",
    "\n",
    "    # 根据这些下标，构造两个数据集的SubsetRandomSampler采样器，它会对下标进行采样\n",
    "    sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "    sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "\n",
    "    # 根据两个采样器来定义加载器，注意将sampler_val和sampler_test分别赋值给了validation_loader和test_loader\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset =test_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                sampler = sampler_val\n",
    "                                               )\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          sampler = sampler_test\n",
    "                                         )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(train_loader,validation_loader,test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,validation_loader, test_loader=dataset(0,4)\n",
    "num_classes = 5  #标签的种类数\n",
    "num_epochs = 100  #训练的总循环周期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签是： 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#随便从数据集中读入一张图片，并绘制出来\n",
    "idx = 1004\n",
    "\n",
    "#dataset支持下标索引，其中提取出来的每一个元素为features，target格式，即属性和标签。[0]表示索引features\n",
    "muteimg = train_dataset[idx][0].numpy()\n",
    "#由于一般的图像包含rgb三个通道，而MINST数据集的图像都是灰度的，只有一个通道。因此，我们忽略通道，把图像看作一个灰度矩阵。\n",
    "#用imshow画图，会将灰度矩阵自动展现为彩色，不同灰度对应不同颜色：从黄到紫\n",
    "\n",
    "plt.imshow(muteimg[0,...])\n",
    "print('标签是：',train_dataset[idx][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、基本的卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 构建网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：在这里，我们将主要调用PyTorch强大的nn.Module这个类来构建卷积神经网络。我们分成如下这几个步骤：\n",
    "\n",
    "1. 首先，我们构造ConvNet类，它是对类nn.Module的继承（即nn.Module是父类，ConvNet为子类。如果这些概念不熟悉，请参考面向对象编程）\n",
    "2. 然后，我们复写__init__，以及forward这两个函数。第一个为构造函数，每当类ConvNet被具体化一个实例的时候，就会调用，forward则是\n",
    "在运行神经网络正向的时候会被自动调用\n",
    "3. 自定义自己的方法\n",
    "\n",
    "另一需要理解的是，ConvNet其实也是一个大容器，它里面有Conv2d，MaxPool2d等组件\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第III课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义卷积神经网络：4和8为人为指定的两个卷积层的厚度（feature map的数量）\n",
    "depth = [4, 8]\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 该函数在创建一个ConvNet对象的时候，即调用如下语句：net=ConvNet()，就会被调用\n",
    "        # 首先调用父类相应的构造函数\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # 其次构造ConvNet需要用到的各个神经模块。\n",
    "        '''注意，定义组件并没有真正搭建这些组件，只是把基本建筑砖块先找好'''\n",
    "        self.conv1 = nn.Conv2d(1, 4, 5, padding = 2) #定义一个卷积层，输入通道为1，输出通道为4，窗口大小为5，padding为2\n",
    "        self.pool = nn.MaxPool2d(2, 2) #定义一个Pooling层，一个窗口为2*2的pooling运算\n",
    "        self.conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2) #第二层卷积，输入通道为depth[0], \n",
    "                                                                   #输出通道为depth[1]，窗口为5，padding为2\n",
    "        self.fc1 = nn.Linear(image_size // 4 * image_size // 4 * depth[1] , 512) \n",
    "                                                            #一个线性连接层，输入尺寸为最后一层立方体的平铺，输出层512个节点\n",
    "        self.fc2 = nn.Linear(512, num_classes) #最后一层线性分类单元，输入为512，输出为要做分类的类别数\n",
    "\n",
    "    def forward(self, x):\n",
    "        #该函数完成神经网络真正的前向运算，我们会在这里把各个组件进行实际的拼装\n",
    "        #x的尺寸：(batch_size, image_channels, image_width, image_height)\n",
    "        x = F.relu(self.conv1(x))  #第一层卷积，激活函数用ReLu，为了防止过拟合\n",
    "        #x的尺寸：(batch_size, num_filters, image_width, image_height)\n",
    "        x = self.pool(x) #第二层pooling，将图片变小\n",
    "        #x的尺寸：(batch_size, depth[0], image_width/2, image_height/2)\n",
    "        x = F.relu(self.conv2(x)) #第三层又是卷积，窗口为5，输入输出通道分别为depth[0]=4, depth[1]=8\n",
    "        #x的尺寸：(batch_size, depth[1], image_width/2, image_height/2)\n",
    "        x = self.pool(x) #第四层pooling，将图片缩小到原大小的1/4\n",
    "        #x的尺寸：(batch_size, depth[1], image_width/4, image_height/4)\n",
    "        \n",
    "        # 将立体的特征图Tensor，压成一个一维的向量\n",
    "        # view这个函数可以将一个tensor按指定的方式重新排布。\n",
    "        # 下面这个命令就是要让x按照batch_size * (image_size//4)^2*depth[1]的方式来排布向量\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        #x的尺寸：(batch_size, depth[1]*image_width/4*image_height/4)\n",
    "        \n",
    "        x = F.relu(self.fc1(x)) #第五层为全链接，ReLu激活函数\n",
    "        #x的尺寸：(batch_size, 512)\n",
    "\n",
    "        x = F.dropout(x, training=self.training) #以默认为0.5的概率对这一层进行dropout操作，为了防止过拟合\n",
    "        x = self.fc2(x) #全链接\n",
    "        #x的尺寸：(batch_size, num_classes)\n",
    "        \n",
    "        x = F.log_softmax(x, dim = 0) #输出层为log_softmax，即概率对数值log(p(x))。采用log_softmax可以使得后面的交叉熵计算更快\n",
    "        return x\n",
    "    \n",
    "    def retrieve_features(self, x):\n",
    "        #该函数专门用于提取卷积神经网络的特征图的功能，返回feature_map1, feature_map2为前两层卷积层的特征图\n",
    "        feature_map1 = F.relu(self.conv1(x)) #完成第一层卷积\n",
    "        x = self.pool(feature_map1)  # 完成第一层pooling\n",
    "        feature_map2 = F.relu(self.conv2(x)) #第二层卷积，两层特征图都存储到了feature_map1, feature_map2中\n",
    "        return (feature_map1, feature_map2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 训练这个卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(541), 2569)\n",
      "训练周期: 0 [0/30596 (0%)]\tLoss: 1.611326\t训练正确率: 23.44%\t校验正确率: 21.06%\n",
      "(tensor(2030), 2569)\n",
      "训练周期: 0 [6400/30596 (21%)]\tLoss: 1.585269\t训练正确率: 32.67%\t校验正确率: 79.02%\n",
      "(tensor(2072), 2569)\n",
      "训练周期: 0 [12800/30596 (42%)]\tLoss: 1.394476\t训练正确率: 45.51%\t校验正确率: 80.65%\n",
      "(tensor(2267), 2569)\n",
      "训练周期: 0 [19200/30596 (63%)]\tLoss: 0.725244\t训练正确率: 55.20%\t校验正确率: 88.24%\n",
      "(tensor(2390), 2569)\n",
      "训练周期: 0 [25600/30596 (84%)]\tLoss: 0.233631\t训练正确率: 63.22%\t校验正确率: 93.03%\n",
      "(tensor(2411), 2569)\n",
      "训练周期: 1 [0/30596 (0%)]\tLoss: 0.193261\t训练正确率: 96.88%\t校验正确率: 93.85%\n",
      "(tensor(2436), 2569)\n",
      "训练周期: 1 [6400/30596 (21%)]\tLoss: 0.378305\t训练正确率: 92.28%\t校验正确率: 94.82%\n",
      "(tensor(2450), 2569)\n",
      "训练周期: 1 [12800/30596 (42%)]\tLoss: 0.109230\t训练正确率: 92.75%\t校验正确率: 95.37%\n",
      "(tensor(2461), 2569)\n",
      "训练周期: 1 [19200/30596 (63%)]\tLoss: 0.205859\t训练正确率: 93.06%\t校验正确率: 95.80%\n",
      "(tensor(2477), 2569)\n",
      "训练周期: 1 [25600/30596 (84%)]\tLoss: 0.249509\t训练正确率: 93.51%\t校验正确率: 96.42%\n",
      "(tensor(2475), 2569)\n",
      "训练周期: 2 [0/30596 (0%)]\tLoss: 0.121131\t训练正确率: 96.88%\t校验正确率: 96.34%\n",
      "(tensor(2480), 2569)\n",
      "训练周期: 2 [6400/30596 (21%)]\tLoss: 0.194822\t训练正确率: 94.99%\t校验正确率: 96.54%\n",
      "(tensor(2492), 2569)\n",
      "训练周期: 2 [12800/30596 (42%)]\tLoss: 0.313362\t训练正确率: 95.16%\t校验正确率: 97.00%\n",
      "(tensor(2496), 2569)\n",
      "训练周期: 2 [19200/30596 (63%)]\tLoss: 0.057576\t训练正确率: 95.30%\t校验正确率: 97.16%\n",
      "(tensor(2494), 2569)\n",
      "训练周期: 2 [25600/30596 (84%)]\tLoss: 0.150646\t训练正确率: 95.41%\t校验正确率: 97.08%\n",
      "(tensor(2496), 2569)\n",
      "训练周期: 3 [0/30596 (0%)]\tLoss: 0.085878\t训练正确率: 96.88%\t校验正确率: 97.16%\n",
      "(tensor(2503), 2569)\n",
      "训练周期: 3 [6400/30596 (21%)]\tLoss: 0.072759\t训练正确率: 96.49%\t校验正确率: 97.43%\n",
      "(tensor(2512), 2569)\n",
      "训练周期: 3 [12800/30596 (42%)]\tLoss: 0.118584\t训练正确率: 96.42%\t校验正确率: 97.78%\n",
      "(tensor(2506), 2569)\n",
      "训练周期: 3 [19200/30596 (63%)]\tLoss: 0.165363\t训练正确率: 96.49%\t校验正确率: 97.55%\n",
      "(tensor(2507), 2569)\n",
      "训练周期: 3 [25600/30596 (84%)]\tLoss: 0.151692\t训练正确率: 96.49%\t校验正确率: 97.59%\n",
      "(tensor(2506), 2569)\n",
      "训练周期: 4 [0/30596 (0%)]\tLoss: 0.121918\t训练正确率: 95.31%\t校验正确率: 97.55%\n",
      "(tensor(2502), 2569)\n",
      "训练周期: 4 [6400/30596 (21%)]\tLoss: 0.077095\t训练正确率: 96.57%\t校验正确率: 97.39%\n",
      "(tensor(2509), 2569)\n",
      "训练周期: 4 [12800/30596 (42%)]\tLoss: 0.101961\t训练正确率: 96.74%\t校验正确率: 97.66%\n",
      "(tensor(2514), 2569)\n",
      "训练周期: 4 [19200/30596 (63%)]\tLoss: 0.037574\t训练正确率: 96.93%\t校验正确率: 97.86%\n",
      "(tensor(2515), 2569)\n",
      "训练周期: 4 [25600/30596 (84%)]\tLoss: 0.028874\t训练正确率: 97.01%\t校验正确率: 97.90%\n",
      "(tensor(2518), 2569)\n",
      "训练周期: 5 [0/30596 (0%)]\tLoss: 0.020066\t训练正确率: 100.00%\t校验正确率: 98.01%\n",
      "(tensor(2529), 2569)\n",
      "训练周期: 5 [6400/30596 (21%)]\tLoss: 0.062305\t训练正确率: 96.61%\t校验正确率: 98.44%\n",
      "(tensor(2522), 2569)\n",
      "训练周期: 5 [12800/30596 (42%)]\tLoss: 0.049642\t训练正确率: 97.05%\t校验正确率: 98.17%\n",
      "(tensor(2512), 2569)\n",
      "训练周期: 5 [19200/30596 (63%)]\tLoss: 0.027653\t训练正确率: 97.10%\t校验正确率: 97.78%\n",
      "(tensor(2520), 2569)\n",
      "训练周期: 5 [25600/30596 (84%)]\tLoss: 0.045999\t训练正确率: 97.24%\t校验正确率: 98.09%\n",
      "(tensor(2518), 2569)\n",
      "训练周期: 6 [0/30596 (0%)]\tLoss: 0.185365\t训练正确率: 96.88%\t校验正确率: 98.01%\n",
      "(tensor(2516), 2569)\n",
      "训练周期: 6 [6400/30596 (21%)]\tLoss: 0.068915\t训练正确率: 97.60%\t校验正确率: 97.94%\n",
      "(tensor(2518), 2569)\n",
      "训练周期: 6 [12800/30596 (42%)]\tLoss: 0.221785\t训练正确率: 97.65%\t校验正确率: 98.01%\n",
      "(tensor(2522), 2569)\n",
      "训练周期: 6 [19200/30596 (63%)]\tLoss: 0.021477\t训练正确率: 97.53%\t校验正确率: 98.17%\n",
      "(tensor(2527), 2569)\n",
      "训练周期: 6 [25600/30596 (84%)]\tLoss: 0.047297\t训练正确率: 97.56%\t校验正确率: 98.37%\n",
      "(tensor(2522), 2569)\n",
      "训练周期: 7 [0/30596 (0%)]\tLoss: 0.113980\t训练正确率: 98.44%\t校验正确率: 98.17%\n",
      "(tensor(2520), 2569)\n",
      "训练周期: 7 [6400/30596 (21%)]\tLoss: 0.088883\t训练正确率: 97.73%\t校验正确率: 98.09%\n",
      "(tensor(2528), 2569)\n",
      "训练周期: 7 [12800/30596 (42%)]\tLoss: 0.188453\t训练正确率: 97.75%\t校验正确率: 98.40%\n",
      "(tensor(2526), 2569)\n",
      "训练周期: 7 [19200/30596 (63%)]\tLoss: 0.053691\t训练正确率: 97.73%\t校验正确率: 98.33%\n",
      "(tensor(2535), 2569)\n",
      "训练周期: 7 [25600/30596 (84%)]\tLoss: 0.064154\t训练正确率: 97.83%\t校验正确率: 98.68%\n",
      "(tensor(2522), 2569)\n",
      "训练周期: 8 [0/30596 (0%)]\tLoss: 0.027840\t训练正确率: 100.00%\t校验正确率: 98.17%\n",
      "(tensor(2532), 2569)\n",
      "训练周期: 8 [6400/30596 (21%)]\tLoss: 0.017600\t训练正确率: 97.88%\t校验正确率: 98.56%\n",
      "(tensor(2535), 2569)\n",
      "训练周期: 8 [12800/30596 (42%)]\tLoss: 0.114870\t训练正确率: 97.78%\t校验正确率: 98.68%\n",
      "(tensor(2527), 2569)\n",
      "训练周期: 8 [19200/30596 (63%)]\tLoss: 0.077076\t训练正确率: 97.77%\t校验正确率: 98.37%\n",
      "(tensor(2534), 2569)\n",
      "训练周期: 8 [25600/30596 (84%)]\tLoss: 0.024410\t训练正确率: 97.83%\t校验正确率: 98.64%\n",
      "(tensor(2528), 2569)\n",
      "训练周期: 9 [0/30596 (0%)]\tLoss: 0.051043\t训练正确率: 98.44%\t校验正确率: 98.40%\n",
      "(tensor(2538), 2569)\n",
      "训练周期: 9 [6400/30596 (21%)]\tLoss: 0.092117\t训练正确率: 98.05%\t校验正确率: 98.79%\n",
      "(tensor(2538), 2569)\n",
      "训练周期: 9 [12800/30596 (42%)]\tLoss: 0.131848\t训练正确率: 98.24%\t校验正确率: 98.79%\n",
      "(tensor(2535), 2569)\n",
      "训练周期: 9 [19200/30596 (63%)]\tLoss: 0.131619\t训练正确率: 98.16%\t校验正确率: 98.68%\n",
      "(tensor(2533), 2569)\n",
      "训练周期: 9 [25600/30596 (84%)]\tLoss: 0.096576\t训练正确率: 98.18%\t校验正确率: 98.60%\n",
      "(tensor(2536), 2569)\n",
      "训练周期: 10 [0/30596 (0%)]\tLoss: 0.013876\t训练正确率: 100.00%\t校验正确率: 98.72%\n",
      "(tensor(2541), 2569)\n",
      "训练周期: 10 [6400/30596 (21%)]\tLoss: 0.083496\t训练正确率: 98.07%\t校验正确率: 98.91%\n",
      "(tensor(2532), 2569)\n",
      "训练周期: 10 [12800/30596 (42%)]\tLoss: 0.042905\t训练正确率: 98.11%\t校验正确率: 98.56%\n",
      "(tensor(2536), 2569)\n",
      "训练周期: 10 [19200/30596 (63%)]\tLoss: 0.148195\t训练正确率: 98.11%\t校验正确率: 98.72%\n",
      "(tensor(2536), 2569)\n",
      "训练周期: 10 [25600/30596 (84%)]\tLoss: 0.012551\t训练正确率: 98.09%\t校验正确率: 98.72%\n",
      "(tensor(2534), 2569)\n",
      "训练周期: 11 [0/30596 (0%)]\tLoss: 0.058773\t训练正确率: 96.88%\t校验正确率: 98.64%\n",
      "(tensor(2530), 2569)\n",
      "训练周期: 11 [6400/30596 (21%)]\tLoss: 0.097346\t训练正确率: 98.28%\t校验正确率: 98.48%\n",
      "(tensor(2536), 2569)\n",
      "训练周期: 11 [12800/30596 (42%)]\tLoss: 0.023949\t训练正确率: 98.34%\t校验正确率: 98.72%\n",
      "(tensor(2536), 2569)\n",
      "训练周期: 11 [19200/30596 (63%)]\tLoss: 0.013338\t训练正确率: 98.28%\t校验正确率: 98.72%\n",
      "(tensor(2533), 2569)\n",
      "训练周期: 11 [25600/30596 (84%)]\tLoss: 0.054741\t训练正确率: 98.25%\t校验正确率: 98.60%\n",
      "(tensor(2541), 2569)\n",
      "训练周期: 12 [0/30596 (0%)]\tLoss: 0.019362\t训练正确率: 100.00%\t校验正确率: 98.91%\n",
      "(tensor(2535), 2569)\n",
      "训练周期: 12 [6400/30596 (21%)]\tLoss: 0.022731\t训练正确率: 98.47%\t校验正确率: 98.68%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 12 [12800/30596 (42%)]\tLoss: 0.011104\t训练正确率: 98.48%\t校验正确率: 98.95%\n",
      "(tensor(2543), 2569)\n",
      "训练周期: 12 [19200/30596 (63%)]\tLoss: 0.011482\t训练正确率: 98.36%\t校验正确率: 98.99%\n",
      "(tensor(2535), 2569)\n",
      "训练周期: 12 [25600/30596 (84%)]\tLoss: 0.034655\t训练正确率: 98.36%\t校验正确率: 98.68%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 13 [0/30596 (0%)]\tLoss: 0.056665\t训练正确率: 96.88%\t校验正确率: 98.95%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 13 [6400/30596 (21%)]\tLoss: 0.048538\t训练正确率: 98.25%\t校验正确率: 98.95%\n",
      "(tensor(2543), 2569)\n",
      "训练周期: 13 [12800/30596 (42%)]\tLoss: 0.031149\t训练正确率: 98.40%\t校验正确率: 98.99%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 13 [19200/30596 (63%)]\tLoss: 0.054396\t训练正确率: 98.40%\t校验正确率: 99.14%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 13 [25600/30596 (84%)]\tLoss: 0.018698\t训练正确率: 98.44%\t校验正确率: 99.14%\n",
      "(tensor(2541), 2569)\n",
      "训练周期: 14 [0/30596 (0%)]\tLoss: 0.025317\t训练正确率: 100.00%\t校验正确率: 98.91%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 14 [6400/30596 (21%)]\tLoss: 0.048200\t训练正确率: 98.27%\t校验正确率: 98.95%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 14 [12800/30596 (42%)]\tLoss: 0.053457\t训练正确率: 98.48%\t校验正确率: 98.95%\n",
      "(tensor(2543), 2569)\n",
      "训练周期: 14 [19200/30596 (63%)]\tLoss: 0.038381\t训练正确率: 98.50%\t校验正确率: 98.99%\n",
      "(tensor(2537), 2569)\n",
      "训练周期: 14 [25600/30596 (84%)]\tLoss: 0.029986\t训练正确率: 98.52%\t校验正确率: 98.75%\n",
      "(tensor(2541), 2569)\n",
      "训练周期: 15 [0/30596 (0%)]\tLoss: 0.057677\t训练正确率: 96.88%\t校验正确率: 98.91%\n",
      "(tensor(2540), 2569)\n",
      "训练周期: 15 [6400/30596 (21%)]\tLoss: 0.025428\t训练正确率: 98.59%\t校验正确率: 98.87%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 15 [12800/30596 (42%)]\tLoss: 0.039629\t训练正确率: 98.57%\t校验正确率: 98.95%\n",
      "(tensor(2540), 2569)\n",
      "训练周期: 15 [19200/30596 (63%)]\tLoss: 0.049623\t训练正确率: 98.58%\t校验正确率: 98.87%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 15 [25600/30596 (84%)]\tLoss: 0.041517\t训练正确率: 98.52%\t校验正确率: 99.14%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 16 [0/30596 (0%)]\tLoss: 0.010921\t训练正确率: 100.00%\t校验正确率: 99.14%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 16 [6400/30596 (21%)]\tLoss: 0.012371\t训练正确率: 98.75%\t校验正确率: 99.14%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 16 [12800/30596 (42%)]\tLoss: 0.024821\t训练正确率: 98.70%\t校验正确率: 98.95%\n",
      "(tensor(2546), 2569)\n",
      "训练周期: 16 [19200/30596 (63%)]\tLoss: 0.034537\t训练正确率: 98.65%\t校验正确率: 99.10%\n",
      "(tensor(2540), 2569)\n",
      "训练周期: 16 [25600/30596 (84%)]\tLoss: 0.106172\t训练正确率: 98.64%\t校验正确率: 98.87%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 17 [0/30596 (0%)]\tLoss: 0.087797\t训练正确率: 96.88%\t校验正确率: 98.95%\n",
      "(tensor(2546), 2569)\n",
      "训练周期: 17 [6400/30596 (21%)]\tLoss: 0.144196\t训练正确率: 98.61%\t校验正确率: 99.10%\n",
      "(tensor(2545), 2569)\n",
      "训练周期: 17 [12800/30596 (42%)]\tLoss: 0.057841\t训练正确率: 98.61%\t校验正确率: 99.07%\n",
      "(tensor(2543), 2569)\n",
      "训练周期: 17 [19200/30596 (63%)]\tLoss: 0.032908\t训练正确率: 98.65%\t校验正确率: 98.99%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 17 [25600/30596 (84%)]\tLoss: 0.023452\t训练正确率: 98.72%\t校验正确率: 99.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2549), 2569)\n",
      "训练周期: 18 [0/30596 (0%)]\tLoss: 0.031081\t训练正确率: 100.00%\t校验正确率: 99.22%\n",
      "(tensor(2544), 2569)\n",
      "训练周期: 18 [6400/30596 (21%)]\tLoss: 0.182973\t训练正确率: 98.82%\t校验正确率: 99.03%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 18 [12800/30596 (42%)]\tLoss: 0.063255\t训练正确率: 98.80%\t校验正确率: 99.34%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 18 [19200/30596 (63%)]\tLoss: 0.100725\t训练正确率: 98.71%\t校验正确率: 99.14%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 18 [25600/30596 (84%)]\tLoss: 0.067082\t训练正确率: 98.70%\t校验正确率: 99.22%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 19 [0/30596 (0%)]\tLoss: 0.017747\t训练正确率: 100.00%\t校验正确率: 99.14%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 19 [6400/30596 (21%)]\tLoss: 0.059279\t训练正确率: 98.73%\t校验正确率: 99.14%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 19 [12800/30596 (42%)]\tLoss: 0.066663\t训练正确率: 98.73%\t校验正确率: 99.14%\n",
      "(tensor(2544), 2569)\n",
      "训练周期: 19 [19200/30596 (63%)]\tLoss: 0.012481\t训练正确率: 98.72%\t校验正确率: 99.03%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 19 [25600/30596 (84%)]\tLoss: 0.004597\t训练正确率: 98.70%\t校验正确率: 99.14%\n",
      "(tensor(2542), 2569)\n",
      "训练周期: 20 [0/30596 (0%)]\tLoss: 0.070820\t训练正确率: 98.44%\t校验正确率: 98.95%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 20 [6400/30596 (21%)]\tLoss: 0.045728\t训练正确率: 98.76%\t校验正确率: 99.22%\n",
      "(tensor(2546), 2569)\n",
      "训练周期: 20 [12800/30596 (42%)]\tLoss: 0.035893\t训练正确率: 98.83%\t校验正确率: 99.10%\n",
      "(tensor(2550), 2569)\n",
      "训练周期: 20 [19200/30596 (63%)]\tLoss: 0.030750\t训练正确率: 98.84%\t校验正确率: 99.26%\n",
      "(tensor(2543), 2569)\n",
      "训练周期: 20 [25600/30596 (84%)]\tLoss: 0.010663\t训练正确率: 98.88%\t校验正确率: 98.99%\n",
      "(tensor(2550), 2569)\n",
      "训练周期: 21 [0/30596 (0%)]\tLoss: 0.027857\t训练正确率: 100.00%\t校验正确率: 99.26%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 21 [6400/30596 (21%)]\tLoss: 0.087429\t训练正确率: 98.95%\t校验正确率: 99.22%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 21 [12800/30596 (42%)]\tLoss: 0.012932\t训练正确率: 98.89%\t校验正确率: 99.30%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 21 [19200/30596 (63%)]\tLoss: 0.002780\t训练正确率: 98.85%\t校验正确率: 99.22%\n",
      "(tensor(2547), 2569)\n",
      "训练周期: 21 [25600/30596 (84%)]\tLoss: 0.030735\t训练正确率: 98.87%\t校验正确率: 99.14%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 22 [0/30596 (0%)]\tLoss: 0.010565\t训练正确率: 100.00%\t校验正确率: 99.22%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 22 [6400/30596 (21%)]\tLoss: 0.015719\t训练正确率: 99.01%\t校验正确率: 99.30%\n",
      "(tensor(2548), 2569)\n",
      "训练周期: 22 [12800/30596 (42%)]\tLoss: 0.016220\t训练正确率: 98.93%\t校验正确率: 99.18%\n",
      "(tensor(2548), 2569)\n",
      "训练周期: 22 [19200/30596 (63%)]\tLoss: 0.017850\t训练正确率: 98.89%\t校验正确率: 99.18%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 22 [25600/30596 (84%)]\tLoss: 0.004015\t训练正确率: 98.91%\t校验正确率: 99.34%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 23 [0/30596 (0%)]\tLoss: 0.026929\t训练正确率: 98.44%\t校验正确率: 99.22%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 23 [6400/30596 (21%)]\tLoss: 0.011721\t训练正确率: 98.82%\t校验正确率: 99.34%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 23 [12800/30596 (42%)]\tLoss: 0.021630\t训练正确率: 98.91%\t校验正确率: 99.30%\n",
      "(tensor(2550), 2569)\n",
      "训练周期: 23 [19200/30596 (63%)]\tLoss: 0.001512\t训练正确率: 98.94%\t校验正确率: 99.26%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 23 [25600/30596 (84%)]\tLoss: 0.036868\t训练正确率: 98.98%\t校验正确率: 99.30%\n",
      "(tensor(2548), 2569)\n",
      "训练周期: 24 [0/30596 (0%)]\tLoss: 0.014587\t训练正确率: 100.00%\t校验正确率: 99.18%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 24 [6400/30596 (21%)]\tLoss: 0.002697\t训练正确率: 98.95%\t校验正确率: 99.42%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 24 [12800/30596 (42%)]\tLoss: 0.019712\t训练正确率: 99.03%\t校验正确率: 99.30%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 24 [19200/30596 (63%)]\tLoss: 0.013184\t训练正确率: 99.06%\t校验正确率: 99.38%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 24 [25600/30596 (84%)]\tLoss: 0.010045\t训练正确率: 98.99%\t校验正确率: 99.42%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 25 [0/30596 (0%)]\tLoss: 0.041226\t训练正确率: 98.44%\t校验正确率: 99.22%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 25 [6400/30596 (21%)]\tLoss: 0.171455\t训练正确率: 98.72%\t校验正确率: 99.22%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 25 [12800/30596 (42%)]\tLoss: 0.016301\t训练正确率: 98.94%\t校验正确率: 99.46%\n",
      "(tensor(2545), 2569)\n",
      "训练周期: 25 [19200/30596 (63%)]\tLoss: 0.020180\t训练正确率: 98.91%\t校验正确率: 99.07%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 25 [25600/30596 (84%)]\tLoss: 0.067751\t训练正确率: 98.92%\t校验正确率: 99.30%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 26 [0/30596 (0%)]\tLoss: 0.015391\t训练正确率: 100.00%\t校验正确率: 99.38%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 26 [6400/30596 (21%)]\tLoss: 0.028124\t训练正确率: 98.93%\t校验正确率: 99.34%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 26 [12800/30596 (42%)]\tLoss: 0.022329\t训练正确率: 98.94%\t校验正确率: 99.42%\n",
      "(tensor(2543), 2569)\n",
      "训练周期: 26 [19200/30596 (63%)]\tLoss: 0.035881\t训练正确率: 98.98%\t校验正确率: 98.99%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 26 [25600/30596 (84%)]\tLoss: 0.065501\t训练正确率: 98.96%\t校验正确率: 99.30%\n",
      "(tensor(2548), 2569)\n",
      "训练周期: 27 [0/30596 (0%)]\tLoss: 0.043966\t训练正确率: 96.88%\t校验正确率: 99.18%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 27 [6400/30596 (21%)]\tLoss: 0.002953\t训练正确率: 99.09%\t校验正确率: 99.34%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 27 [12800/30596 (42%)]\tLoss: 0.027592\t训练正确率: 99.08%\t校验正确率: 99.34%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 27 [19200/30596 (63%)]\tLoss: 0.015565\t训练正确率: 99.13%\t校验正确率: 99.46%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 27 [25600/30596 (84%)]\tLoss: 0.028259\t训练正确率: 99.07%\t校验正确率: 99.34%\n",
      "(tensor(2546), 2569)\n",
      "训练周期: 28 [0/30596 (0%)]\tLoss: 0.020888\t训练正确率: 100.00%\t校验正确率: 99.10%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 28 [6400/30596 (21%)]\tLoss: 0.032153\t训练正确率: 98.95%\t校验正确率: 99.38%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 28 [12800/30596 (42%)]\tLoss: 0.008791\t训练正确率: 98.94%\t校验正确率: 99.42%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 28 [19200/30596 (63%)]\tLoss: 0.045507\t训练正确率: 98.94%\t校验正确率: 99.46%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 28 [25600/30596 (84%)]\tLoss: 0.004700\t训练正确率: 98.92%\t校验正确率: 99.30%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 29 [0/30596 (0%)]\tLoss: 0.012186\t训练正确率: 100.00%\t校验正确率: 99.46%\n",
      "(tensor(2549), 2569)\n",
      "训练周期: 29 [6400/30596 (21%)]\tLoss: 0.033692\t训练正确率: 98.92%\t校验正确率: 99.22%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 29 [12800/30596 (42%)]\tLoss: 0.007266\t训练正确率: 98.91%\t校验正确率: 99.30%\n",
      "(tensor(2550), 2569)\n",
      "训练周期: 29 [19200/30596 (63%)]\tLoss: 0.029589\t训练正确率: 98.95%\t校验正确率: 99.26%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 29 [25600/30596 (84%)]\tLoss: 0.019131\t训练正确率: 98.96%\t校验正确率: 99.46%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 30 [0/30596 (0%)]\tLoss: 0.034062\t训练正确率: 98.44%\t校验正确率: 99.46%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 30 [6400/30596 (21%)]\tLoss: 0.032234\t训练正确率: 99.15%\t校验正确率: 99.42%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 30 [12800/30596 (42%)]\tLoss: 0.005466\t训练正确率: 99.18%\t校验正确率: 99.42%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 30 [19200/30596 (63%)]\tLoss: 0.004510\t训练正确率: 99.12%\t校验正确率: 99.30%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 30 [25600/30596 (84%)]\tLoss: 0.010798\t训练正确率: 99.13%\t校验正确率: 99.46%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 31 [0/30596 (0%)]\tLoss: 0.031556\t训练正确率: 100.00%\t校验正确率: 99.57%\n",
      "(tensor(2548), 2569)\n",
      "训练周期: 31 [6400/30596 (21%)]\tLoss: 0.005406\t训练正确率: 99.01%\t校验正确率: 99.18%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 31 [12800/30596 (42%)]\tLoss: 0.009440\t训练正确率: 99.04%\t校验正确率: 99.42%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 31 [19200/30596 (63%)]\tLoss: 0.013912\t训练正确率: 99.02%\t校验正确率: 99.42%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 31 [25600/30596 (84%)]\tLoss: 0.008772\t训练正确率: 99.07%\t校验正确率: 99.49%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 32 [0/30596 (0%)]\tLoss: 0.009170\t训练正确率: 100.00%\t校验正确率: 99.46%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 32 [6400/30596 (21%)]\tLoss: 0.102718\t训练正确率: 99.01%\t校验正确率: 99.42%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 32 [12800/30596 (42%)]\tLoss: 0.014269\t训练正确率: 98.90%\t校验正确率: 99.46%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 32 [19200/30596 (63%)]\tLoss: 0.031407\t训练正确率: 98.95%\t校验正确率: 99.38%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 32 [25600/30596 (84%)]\tLoss: 0.005370\t训练正确率: 99.05%\t校验正确率: 99.38%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 33 [0/30596 (0%)]\tLoss: 0.001876\t训练正确率: 100.00%\t校验正确率: 99.49%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 33 [6400/30596 (21%)]\tLoss: 0.019432\t训练正确率: 99.20%\t校验正确率: 99.34%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 33 [12800/30596 (42%)]\tLoss: 0.031326\t训练正确率: 99.15%\t校验正确率: 99.34%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 33 [19200/30596 (63%)]\tLoss: 0.001362\t训练正确率: 99.18%\t校验正确率: 99.30%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 33 [25600/30596 (84%)]\tLoss: 0.006093\t训练正确率: 99.19%\t校验正确率: 99.38%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 34 [0/30596 (0%)]\tLoss: 0.003034\t训练正确率: 100.00%\t校验正确率: 99.42%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 34 [6400/30596 (21%)]\tLoss: 0.008523\t训练正确率: 98.95%\t校验正确率: 99.53%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 34 [12800/30596 (42%)]\tLoss: 0.031350\t训练正确率: 98.97%\t校验正确率: 99.53%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 34 [19200/30596 (63%)]\tLoss: 0.009119\t训练正确率: 98.98%\t校验正确率: 99.42%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 34 [25600/30596 (84%)]\tLoss: 0.005585\t训练正确率: 99.06%\t校验正确率: 99.53%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 35 [0/30596 (0%)]\tLoss: 0.016173\t训练正确率: 98.44%\t校验正确率: 99.30%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 35 [6400/30596 (21%)]\tLoss: 0.053614\t训练正确率: 99.26%\t校验正确率: 99.42%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 35 [12800/30596 (42%)]\tLoss: 0.011464\t训练正确率: 99.19%\t校验正确率: 99.49%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 35 [19200/30596 (63%)]\tLoss: 0.081184\t训练正确率: 99.13%\t校验正确率: 99.38%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 35 [25600/30596 (84%)]\tLoss: 0.005643\t训练正确率: 99.17%\t校验正确率: 99.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2556), 2569)\n",
      "训练周期: 36 [0/30596 (0%)]\tLoss: 0.007208\t训练正确率: 100.00%\t校验正确率: 99.49%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 36 [6400/30596 (21%)]\tLoss: 0.004740\t训练正确率: 99.23%\t校验正确率: 99.49%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 36 [12800/30596 (42%)]\tLoss: 0.146531\t训练正确率: 99.23%\t校验正确率: 99.49%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 36 [19200/30596 (63%)]\tLoss: 0.022630\t训练正确率: 99.18%\t校验正确率: 99.57%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 36 [25600/30596 (84%)]\tLoss: 0.016445\t训练正确率: 99.21%\t校验正确率: 99.53%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 37 [0/30596 (0%)]\tLoss: 0.039641\t训练正确率: 96.88%\t校验正确率: 99.53%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 37 [6400/30596 (21%)]\tLoss: 0.013911\t训练正确率: 98.99%\t校验正确率: 99.38%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 37 [12800/30596 (42%)]\tLoss: 0.168822\t训练正确率: 99.02%\t校验正确率: 99.53%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 37 [19200/30596 (63%)]\tLoss: 0.001930\t训练正确率: 99.11%\t校验正确率: 99.42%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 37 [25600/30596 (84%)]\tLoss: 0.005462\t训练正确率: 99.12%\t校验正确率: 99.53%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 38 [0/30596 (0%)]\tLoss: 0.009400\t训练正确率: 100.00%\t校验正确率: 99.49%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 38 [6400/30596 (21%)]\tLoss: 0.003412\t训练正确率: 99.15%\t校验正确率: 99.46%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 38 [12800/30596 (42%)]\tLoss: 0.002633\t训练正确率: 99.14%\t校验正确率: 99.53%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 38 [19200/30596 (63%)]\tLoss: 0.023817\t训练正确率: 99.17%\t校验正确率: 99.65%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 38 [25600/30596 (84%)]\tLoss: 0.002337\t训练正确率: 99.19%\t校验正确率: 99.53%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 39 [0/30596 (0%)]\tLoss: 0.078910\t训练正确率: 98.44%\t校验正确率: 99.57%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 39 [6400/30596 (21%)]\tLoss: 0.004277\t训练正确率: 99.01%\t校验正确率: 99.61%\n",
      "(tensor(2551), 2569)\n",
      "训练周期: 39 [12800/30596 (42%)]\tLoss: 0.007778\t训练正确率: 99.20%\t校验正确率: 99.30%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 39 [19200/30596 (63%)]\tLoss: 0.011822\t训练正确率: 99.24%\t校验正确率: 99.53%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 39 [25600/30596 (84%)]\tLoss: 0.004485\t训练正确率: 99.20%\t校验正确率: 99.42%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 40 [0/30596 (0%)]\tLoss: 0.002280\t训练正确率: 100.00%\t校验正确率: 99.49%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 40 [6400/30596 (21%)]\tLoss: 0.028424\t训练正确率: 99.16%\t校验正确率: 99.57%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 40 [12800/30596 (42%)]\tLoss: 0.020261\t训练正确率: 99.35%\t校验正确率: 99.73%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 40 [19200/30596 (63%)]\tLoss: 0.009397\t训练正确率: 99.30%\t校验正确率: 99.57%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 40 [25600/30596 (84%)]\tLoss: 0.003208\t训练正确率: 99.29%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 41 [0/30596 (0%)]\tLoss: 0.031381\t训练正确率: 98.44%\t校验正确率: 99.61%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 41 [6400/30596 (21%)]\tLoss: 0.022734\t训练正确率: 99.24%\t校验正确率: 99.49%\n",
      "(tensor(2552), 2569)\n",
      "训练周期: 41 [12800/30596 (42%)]\tLoss: 0.006951\t训练正确率: 99.22%\t校验正确率: 99.34%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 41 [19200/30596 (63%)]\tLoss: 0.014993\t训练正确率: 99.19%\t校验正确率: 99.57%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 41 [25600/30596 (84%)]\tLoss: 0.054468\t训练正确率: 99.25%\t校验正确率: 99.53%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 42 [0/30596 (0%)]\tLoss: 0.001963\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 42 [6400/30596 (21%)]\tLoss: 0.012543\t训练正确率: 99.29%\t校验正确率: 99.38%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 42 [12800/30596 (42%)]\tLoss: 0.015866\t训练正确率: 99.38%\t校验正确率: 99.53%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 42 [19200/30596 (63%)]\tLoss: 0.009353\t训练正确率: 99.40%\t校验正确率: 99.65%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 42 [25600/30596 (84%)]\tLoss: 0.020526\t训练正确率: 99.39%\t校验正确率: 99.49%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 43 [0/30596 (0%)]\tLoss: 0.001704\t训练正确率: 100.00%\t校验正确率: 99.53%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 43 [6400/30596 (21%)]\tLoss: 0.037072\t训练正确率: 99.21%\t校验正确率: 99.65%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 43 [12800/30596 (42%)]\tLoss: 0.061472\t训练正确率: 99.27%\t校验正确率: 99.46%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 43 [19200/30596 (63%)]\tLoss: 0.172505\t训练正确率: 99.28%\t校验正确率: 99.53%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 43 [25600/30596 (84%)]\tLoss: 0.002295\t训练正确率: 99.30%\t校验正确率: 99.61%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 44 [0/30596 (0%)]\tLoss: 0.041425\t训练正确率: 98.44%\t校验正确率: 99.53%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 44 [6400/30596 (21%)]\tLoss: 0.000738\t训练正确率: 99.37%\t校验正确率: 99.53%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 44 [12800/30596 (42%)]\tLoss: 0.053625\t训练正确率: 99.31%\t校验正确率: 99.57%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 44 [19200/30596 (63%)]\tLoss: 0.001310\t训练正确率: 99.32%\t校验正确率: 99.49%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 44 [25600/30596 (84%)]\tLoss: 0.005875\t训练正确率: 99.36%\t校验正确率: 99.53%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 45 [0/30596 (0%)]\tLoss: 0.025950\t训练正确率: 98.44%\t校验正确率: 99.57%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 45 [6400/30596 (21%)]\tLoss: 0.079339\t训练正确率: 99.40%\t校验正确率: 99.42%\n",
      "(tensor(2548), 2569)\n",
      "训练周期: 45 [12800/30596 (42%)]\tLoss: 0.036229\t训练正确率: 99.25%\t校验正确率: 99.18%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 45 [19200/30596 (63%)]\tLoss: 0.011910\t训练正确率: 99.29%\t校验正确率: 99.46%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 45 [25600/30596 (84%)]\tLoss: 0.045032\t训练正确率: 99.30%\t校验正确率: 99.65%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 46 [0/30596 (0%)]\tLoss: 0.013877\t训练正确率: 100.00%\t校验正确率: 99.38%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 46 [6400/30596 (21%)]\tLoss: 0.007664\t训练正确率: 99.38%\t校验正确率: 99.49%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 46 [12800/30596 (42%)]\tLoss: 0.010123\t训练正确率: 99.43%\t校验正确率: 99.42%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 46 [19200/30596 (63%)]\tLoss: 0.002584\t训练正确率: 99.42%\t校验正确率: 99.57%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 46 [25600/30596 (84%)]\tLoss: 0.001752\t训练正确率: 99.39%\t校验正确率: 99.53%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 47 [0/30596 (0%)]\tLoss: 0.008550\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 47 [6400/30596 (21%)]\tLoss: 0.002562\t训练正确率: 99.18%\t校验正确率: 99.53%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 47 [12800/30596 (42%)]\tLoss: 0.005975\t训练正确率: 99.26%\t校验正确率: 99.69%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 47 [19200/30596 (63%)]\tLoss: 0.001486\t训练正确率: 99.29%\t校验正确率: 99.61%\n",
      "(tensor(2553), 2569)\n",
      "训练周期: 47 [25600/30596 (84%)]\tLoss: 0.003640\t训练正确率: 99.37%\t校验正确率: 99.38%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 48 [0/30596 (0%)]\tLoss: 0.001065\t训练正确率: 100.00%\t校验正确率: 99.57%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 48 [6400/30596 (21%)]\tLoss: 0.005985\t训练正确率: 99.24%\t校验正确率: 99.49%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 48 [12800/30596 (42%)]\tLoss: 0.025111\t训练正确率: 99.22%\t校验正确率: 99.57%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 48 [19200/30596 (63%)]\tLoss: 0.020662\t训练正确率: 99.29%\t校验正确率: 99.65%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 48 [25600/30596 (84%)]\tLoss: 0.002309\t训练正确率: 99.37%\t校验正确率: 99.46%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 49 [0/30596 (0%)]\tLoss: 0.004671\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 49 [6400/30596 (21%)]\tLoss: 0.002562\t训练正确率: 99.47%\t校验正确率: 99.53%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 49 [12800/30596 (42%)]\tLoss: 0.020404\t训练正确率: 99.42%\t校验正确率: 99.69%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 49 [19200/30596 (63%)]\tLoss: 0.004150\t训练正确率: 99.40%\t校验正确率: 99.57%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 49 [25600/30596 (84%)]\tLoss: 0.004722\t训练正确率: 99.42%\t校验正确率: 99.69%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 50 [0/30596 (0%)]\tLoss: 0.016589\t训练正确率: 98.44%\t校验正确率: 99.46%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 50 [6400/30596 (21%)]\tLoss: 0.001946\t训练正确率: 99.35%\t校验正确率: 99.65%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 50 [12800/30596 (42%)]\tLoss: 0.020665\t训练正确率: 99.33%\t校验正确率: 99.61%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 50 [19200/30596 (63%)]\tLoss: 0.010242\t训练正确率: 99.40%\t校验正确率: 99.46%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 50 [25600/30596 (84%)]\tLoss: 0.002600\t训练正确率: 99.44%\t校验正确率: 99.61%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 51 [0/30596 (0%)]\tLoss: 0.066280\t训练正确率: 98.44%\t校验正确率: 99.57%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 51 [6400/30596 (21%)]\tLoss: 0.069611\t训练正确率: 99.47%\t校验正确率: 99.65%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 51 [12800/30596 (42%)]\tLoss: 0.052310\t训练正确率: 99.53%\t校验正确率: 99.57%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 51 [19200/30596 (63%)]\tLoss: 0.002615\t训练正确率: 99.49%\t校验正确率: 99.49%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 51 [25600/30596 (84%)]\tLoss: 0.006006\t训练正确率: 99.47%\t校验正确率: 99.46%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 52 [0/30596 (0%)]\tLoss: 0.027597\t训练正确率: 98.44%\t校验正确率: 99.49%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 52 [6400/30596 (21%)]\tLoss: 0.008056\t训练正确率: 99.37%\t校验正确率: 99.53%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 52 [12800/30596 (42%)]\tLoss: 0.001097\t训练正确率: 99.42%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 52 [19200/30596 (63%)]\tLoss: 0.002428\t训练正确率: 99.42%\t校验正确率: 99.73%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 52 [25600/30596 (84%)]\tLoss: 0.007642\t训练正确率: 99.44%\t校验正确率: 99.57%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 53 [0/30596 (0%)]\tLoss: 0.010116\t训练正确率: 100.00%\t校验正确率: 99.57%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 53 [6400/30596 (21%)]\tLoss: 0.000547\t训练正确率: 99.57%\t校验正确率: 99.61%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 53 [12800/30596 (42%)]\tLoss: 0.020313\t训练正确率: 99.43%\t校验正确率: 99.69%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 53 [19200/30596 (63%)]\tLoss: 0.012482\t训练正确率: 99.42%\t校验正确率: 99.49%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 53 [25600/30596 (84%)]\tLoss: 0.008893\t训练正确率: 99.45%\t校验正确率: 99.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2556), 2569)\n",
      "训练周期: 54 [0/30596 (0%)]\tLoss: 0.006624\t训练正确率: 100.00%\t校验正确率: 99.49%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 54 [6400/30596 (21%)]\tLoss: 0.024550\t训练正确率: 99.07%\t校验正确率: 99.65%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 54 [12800/30596 (42%)]\tLoss: 0.026872\t训练正确率: 99.25%\t校验正确率: 99.49%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 54 [19200/30596 (63%)]\tLoss: 0.000726\t训练正确率: 99.28%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 54 [25600/30596 (84%)]\tLoss: 0.003893\t训练正确率: 99.33%\t校验正确率: 99.69%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 55 [0/30596 (0%)]\tLoss: 0.000971\t训练正确率: 100.00%\t校验正确率: 99.57%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 55 [6400/30596 (21%)]\tLoss: 0.015593\t训练正确率: 99.54%\t校验正确率: 99.42%\n",
      "(tensor(2554), 2569)\n",
      "训练周期: 55 [12800/30596 (42%)]\tLoss: 0.034165\t训练正确率: 99.52%\t校验正确率: 99.42%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 55 [19200/30596 (63%)]\tLoss: 0.011158\t训练正确率: 99.49%\t校验正确率: 99.53%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 55 [25600/30596 (84%)]\tLoss: 0.096794\t训练正确率: 99.44%\t校验正确率: 99.49%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 56 [0/30596 (0%)]\tLoss: 0.123982\t训练正确率: 96.88%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 56 [6400/30596 (21%)]\tLoss: 0.009437\t训练正确率: 99.46%\t校验正确率: 99.69%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 56 [12800/30596 (42%)]\tLoss: 0.016317\t训练正确率: 99.50%\t校验正确率: 99.61%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 56 [19200/30596 (63%)]\tLoss: 0.037644\t训练正确率: 99.49%\t校验正确率: 99.53%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 56 [25600/30596 (84%)]\tLoss: 0.002158\t训练正确率: 99.46%\t校验正确率: 99.61%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 57 [0/30596 (0%)]\tLoss: 0.004001\t训练正确率: 100.00%\t校验正确率: 99.53%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 57 [6400/30596 (21%)]\tLoss: 0.008110\t训练正确率: 99.27%\t校验正确率: 99.46%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 57 [12800/30596 (42%)]\tLoss: 0.018450\t训练正确率: 99.37%\t校验正确率: 99.61%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 57 [19200/30596 (63%)]\tLoss: 0.002095\t训练正确率: 99.41%\t校验正确率: 99.57%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 57 [25600/30596 (84%)]\tLoss: 0.023143\t训练正确率: 99.43%\t校验正确率: 99.57%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 58 [0/30596 (0%)]\tLoss: 0.005642\t训练正确率: 100.00%\t校验正确率: 99.57%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 58 [6400/30596 (21%)]\tLoss: 0.002774\t训练正确率: 99.49%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 58 [12800/30596 (42%)]\tLoss: 0.008472\t训练正确率: 99.50%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 58 [19200/30596 (63%)]\tLoss: 0.008740\t训练正确率: 99.58%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 58 [25600/30596 (84%)]\tLoss: 0.012159\t训练正确率: 99.55%\t校验正确率: 99.69%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 59 [0/30596 (0%)]\tLoss: 0.006032\t训练正确率: 100.00%\t校验正确率: 99.57%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 59 [6400/30596 (21%)]\tLoss: 0.002418\t训练正确率: 99.61%\t校验正确率: 99.61%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 59 [12800/30596 (42%)]\tLoss: 0.060915\t训练正确率: 99.55%\t校验正确率: 99.65%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 59 [19200/30596 (63%)]\tLoss: 0.005812\t训练正确率: 99.58%\t校验正确率: 99.57%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 59 [25600/30596 (84%)]\tLoss: 0.095654\t训练正确率: 99.58%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 60 [0/30596 (0%)]\tLoss: 0.001095\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 60 [6400/30596 (21%)]\tLoss: 0.001545\t训练正确率: 99.68%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 60 [12800/30596 (42%)]\tLoss: 0.003828\t训练正确率: 99.58%\t校验正确率: 99.73%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 60 [19200/30596 (63%)]\tLoss: 0.002025\t训练正确率: 99.56%\t校验正确率: 99.46%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 60 [25600/30596 (84%)]\tLoss: 0.001286\t训练正确率: 99.56%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 61 [0/30596 (0%)]\tLoss: 0.005837\t训练正确率: 100.00%\t校验正确率: 99.61%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 61 [6400/30596 (21%)]\tLoss: 0.005902\t训练正确率: 99.38%\t校验正确率: 99.57%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 61 [12800/30596 (42%)]\tLoss: 0.024314\t训练正确率: 99.45%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 61 [19200/30596 (63%)]\tLoss: 0.013641\t训练正确率: 99.47%\t校验正确率: 99.61%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 61 [25600/30596 (84%)]\tLoss: 0.016643\t训练正确率: 99.47%\t校验正确率: 99.77%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 62 [0/30596 (0%)]\tLoss: 0.038741\t训练正确率: 98.44%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 62 [6400/30596 (21%)]\tLoss: 0.008781\t训练正确率: 99.54%\t校验正确率: 99.65%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 62 [12800/30596 (42%)]\tLoss: 0.043909\t训练正确率: 99.42%\t校验正确率: 99.57%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 62 [19200/30596 (63%)]\tLoss: 0.008098\t训练正确率: 99.43%\t校验正确率: 99.53%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 62 [25600/30596 (84%)]\tLoss: 0.001352\t训练正确率: 99.45%\t校验正确率: 99.57%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 63 [0/30596 (0%)]\tLoss: 0.001007\t训练正确率: 100.00%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 63 [6400/30596 (21%)]\tLoss: 0.004320\t训练正确率: 99.60%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 63 [12800/30596 (42%)]\tLoss: 0.000847\t训练正确率: 99.56%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 63 [19200/30596 (63%)]\tLoss: 0.002734\t训练正确率: 99.58%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 63 [25600/30596 (84%)]\tLoss: 0.009429\t训练正确率: 99.58%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 64 [0/30596 (0%)]\tLoss: 0.014241\t训练正确率: 100.00%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 64 [6400/30596 (21%)]\tLoss: 0.001740\t训练正确率: 99.68%\t校验正确率: 99.73%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 64 [12800/30596 (42%)]\tLoss: 0.013611\t训练正确率: 99.64%\t校验正确率: 99.77%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 64 [19200/30596 (63%)]\tLoss: 0.003529\t训练正确率: 99.61%\t校验正确率: 99.81%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 64 [25600/30596 (84%)]\tLoss: 0.002249\t训练正确率: 99.61%\t校验正确率: 99.77%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 65 [0/30596 (0%)]\tLoss: 0.023502\t训练正确率: 98.44%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 65 [6400/30596 (21%)]\tLoss: 0.049735\t训练正确率: 99.54%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 65 [12800/30596 (42%)]\tLoss: 0.004309\t训练正确率: 99.53%\t校验正确率: 99.73%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 65 [19200/30596 (63%)]\tLoss: 0.020618\t训练正确率: 99.54%\t校验正确率: 99.49%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 65 [25600/30596 (84%)]\tLoss: 0.029352\t训练正确率: 99.57%\t校验正确率: 99.53%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 66 [0/30596 (0%)]\tLoss: 0.035799\t训练正确率: 98.44%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 66 [6400/30596 (21%)]\tLoss: 0.004485\t训练正确率: 99.54%\t校验正确率: 99.65%\n",
      "(tensor(2555), 2569)\n",
      "训练周期: 66 [12800/30596 (42%)]\tLoss: 0.017721\t训练正确率: 99.53%\t校验正确率: 99.46%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 66 [19200/30596 (63%)]\tLoss: 0.036822\t训练正确率: 99.48%\t校验正确率: 99.73%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 66 [25600/30596 (84%)]\tLoss: 0.004648\t训练正确率: 99.52%\t校验正确率: 99.61%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 67 [0/30596 (0%)]\tLoss: 0.000337\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 67 [6400/30596 (21%)]\tLoss: 0.009574\t训练正确率: 99.58%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 67 [12800/30596 (42%)]\tLoss: 0.009909\t训练正确率: 99.62%\t校验正确率: 99.65%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 67 [19200/30596 (63%)]\tLoss: 0.001130\t训练正确率: 99.61%\t校验正确率: 99.57%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 67 [25600/30596 (84%)]\tLoss: 0.000750\t训练正确率: 99.62%\t校验正确率: 99.65%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 68 [0/30596 (0%)]\tLoss: 0.052298\t训练正确率: 96.88%\t校验正确率: 99.73%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 68 [6400/30596 (21%)]\tLoss: 0.000417\t训练正确率: 99.49%\t校验正确率: 99.77%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 68 [12800/30596 (42%)]\tLoss: 0.001903\t训练正确率: 99.57%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 68 [19200/30596 (63%)]\tLoss: 0.001309\t训练正确率: 99.57%\t校验正确率: 99.69%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 68 [25600/30596 (84%)]\tLoss: 0.003936\t训练正确率: 99.60%\t校验正确率: 99.57%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 69 [0/30596 (0%)]\tLoss: 0.037714\t训练正确率: 98.44%\t校验正确率: 99.73%\n",
      "(tensor(2565), 2569)\n",
      "训练周期: 69 [6400/30596 (21%)]\tLoss: 0.037396\t训练正确率: 99.58%\t校验正确率: 99.84%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 69 [12800/30596 (42%)]\tLoss: 0.003551\t训练正确率: 99.55%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 69 [19200/30596 (63%)]\tLoss: 0.002200\t训练正确率: 99.58%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 69 [25600/30596 (84%)]\tLoss: 0.003461\t训练正确率: 99.62%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 70 [0/30596 (0%)]\tLoss: 0.004579\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 70 [6400/30596 (21%)]\tLoss: 0.019830\t训练正确率: 99.47%\t校验正确率: 99.77%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 70 [12800/30596 (42%)]\tLoss: 0.018452\t训练正确率: 99.56%\t校验正确率: 99.77%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 70 [19200/30596 (63%)]\tLoss: 0.004430\t训练正确率: 99.54%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 70 [25600/30596 (84%)]\tLoss: 0.022065\t训练正确率: 99.51%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 71 [0/30596 (0%)]\tLoss: 0.008015\t训练正确率: 100.00%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 71 [6400/30596 (21%)]\tLoss: 0.022204\t训练正确率: 99.58%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 71 [12800/30596 (42%)]\tLoss: 0.001108\t训练正确率: 99.66%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 71 [19200/30596 (63%)]\tLoss: 0.006133\t训练正确率: 99.68%\t校验正确率: 99.65%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 71 [25600/30596 (84%)]\tLoss: 0.001605\t训练正确率: 99.65%\t校验正确率: 99.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2560), 2569)\n",
      "训练周期: 72 [0/30596 (0%)]\tLoss: 0.004547\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 72 [6400/30596 (21%)]\tLoss: 0.002875\t训练正确率: 99.50%\t校验正确率: 99.61%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 72 [12800/30596 (42%)]\tLoss: 0.005985\t训练正确率: 99.56%\t校验正确率: 99.65%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 72 [19200/30596 (63%)]\tLoss: 0.001319\t训练正确率: 99.56%\t校验正确率: 99.61%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 72 [25600/30596 (84%)]\tLoss: 0.002793\t训练正确率: 99.56%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 73 [0/30596 (0%)]\tLoss: 0.007319\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 73 [6400/30596 (21%)]\tLoss: 0.001775\t训练正确率: 99.61%\t校验正确率: 99.65%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 73 [12800/30596 (42%)]\tLoss: 0.002228\t训练正确率: 99.60%\t校验正确率: 99.61%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 73 [19200/30596 (63%)]\tLoss: 0.000799\t训练正确率: 99.62%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 73 [25600/30596 (84%)]\tLoss: 0.010426\t训练正确率: 99.62%\t校验正确率: 99.69%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 74 [0/30596 (0%)]\tLoss: 0.001790\t训练正确率: 100.00%\t校验正确率: 99.53%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 74 [6400/30596 (21%)]\tLoss: 0.004128\t训练正确率: 99.71%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 74 [12800/30596 (42%)]\tLoss: 0.000264\t训练正确率: 99.69%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 74 [19200/30596 (63%)]\tLoss: 0.042788\t训练正确率: 99.67%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 74 [25600/30596 (84%)]\tLoss: 0.005419\t训练正确率: 99.64%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 75 [0/30596 (0%)]\tLoss: 0.002314\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 75 [6400/30596 (21%)]\tLoss: 0.007986\t训练正确率: 99.71%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 75 [12800/30596 (42%)]\tLoss: 0.002182\t训练正确率: 99.70%\t校验正确率: 99.61%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 75 [19200/30596 (63%)]\tLoss: 0.002117\t训练正确率: 99.66%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 75 [25600/30596 (84%)]\tLoss: 0.001547\t训练正确率: 99.66%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 76 [0/30596 (0%)]\tLoss: 0.004329\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 76 [6400/30596 (21%)]\tLoss: 0.000978\t训练正确率: 99.71%\t校验正确率: 99.53%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 76 [12800/30596 (42%)]\tLoss: 0.000487\t训练正确率: 99.70%\t校验正确率: 99.65%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 76 [19200/30596 (63%)]\tLoss: 0.008389\t训练正确率: 99.67%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 76 [25600/30596 (84%)]\tLoss: 0.002849\t训练正确率: 99.66%\t校验正确率: 99.69%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 77 [0/30596 (0%)]\tLoss: 0.031207\t训练正确率: 98.44%\t校验正确率: 99.57%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 77 [6400/30596 (21%)]\tLoss: 0.000596\t训练正确率: 99.63%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 77 [12800/30596 (42%)]\tLoss: 0.004767\t训练正确率: 99.63%\t校验正确率: 99.65%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 77 [19200/30596 (63%)]\tLoss: 0.002422\t训练正确率: 99.68%\t校验正确率: 99.53%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 77 [25600/30596 (84%)]\tLoss: 0.001152\t训练正确率: 99.66%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 78 [0/30596 (0%)]\tLoss: 0.002198\t训练正确率: 100.00%\t校验正确率: 99.73%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 78 [6400/30596 (21%)]\tLoss: 0.002843\t训练正确率: 99.77%\t校验正确率: 99.57%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 78 [12800/30596 (42%)]\tLoss: 0.000274\t训练正确率: 99.72%\t校验正确率: 99.73%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 78 [19200/30596 (63%)]\tLoss: 0.000878\t训练正确率: 99.69%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 78 [25600/30596 (84%)]\tLoss: 0.000588\t训练正确率: 99.69%\t校验正确率: 99.61%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 79 [0/30596 (0%)]\tLoss: 0.011626\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2556), 2569)\n",
      "训练周期: 79 [6400/30596 (21%)]\tLoss: 0.004006\t训练正确率: 99.66%\t校验正确率: 99.49%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 79 [12800/30596 (42%)]\tLoss: 0.007833\t训练正确率: 99.60%\t校验正确率: 99.69%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 79 [19200/30596 (63%)]\tLoss: 0.002723\t训练正确率: 99.63%\t校验正确率: 99.61%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 79 [25600/30596 (84%)]\tLoss: 0.014338\t训练正确率: 99.63%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 80 [0/30596 (0%)]\tLoss: 0.005114\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 80 [6400/30596 (21%)]\tLoss: 0.000859\t训练正确率: 99.58%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 80 [12800/30596 (42%)]\tLoss: 0.003613\t训练正确率: 99.61%\t校验正确率: 99.69%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 80 [19200/30596 (63%)]\tLoss: 0.022586\t训练正确率: 99.65%\t校验正确率: 99.77%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 80 [25600/30596 (84%)]\tLoss: 0.000206\t训练正确率: 99.63%\t校验正确率: 99.81%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 81 [0/30596 (0%)]\tLoss: 0.055414\t训练正确率: 98.44%\t校验正确率: 99.69%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 81 [6400/30596 (21%)]\tLoss: 0.001804\t训练正确率: 99.46%\t校验正确率: 99.61%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 81 [12800/30596 (42%)]\tLoss: 0.000922\t训练正确率: 99.54%\t校验正确率: 99.57%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 81 [19200/30596 (63%)]\tLoss: 0.035305\t训练正确率: 99.55%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 81 [25600/30596 (84%)]\tLoss: 0.018405\t训练正确率: 99.58%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 82 [0/30596 (0%)]\tLoss: 0.003262\t训练正确率: 100.00%\t校验正确率: 99.61%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 82 [6400/30596 (21%)]\tLoss: 0.001668\t训练正确率: 99.63%\t校验正确率: 99.65%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 82 [12800/30596 (42%)]\tLoss: 0.001749\t训练正确率: 99.62%\t校验正确率: 99.65%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 82 [19200/30596 (63%)]\tLoss: 0.008194\t训练正确率: 99.64%\t校验正确率: 99.77%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 82 [25600/30596 (84%)]\tLoss: 0.014689\t训练正确率: 99.65%\t校验正确率: 99.69%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 83 [0/30596 (0%)]\tLoss: 0.012084\t训练正确率: 100.00%\t校验正确率: 99.77%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 83 [6400/30596 (21%)]\tLoss: 0.001912\t训练正确率: 99.71%\t校验正确率: 99.77%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 83 [12800/30596 (42%)]\tLoss: 0.008453\t训练正确率: 99.63%\t校验正确率: 99.81%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 83 [19200/30596 (63%)]\tLoss: 0.016809\t训练正确率: 99.67%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 83 [25600/30596 (84%)]\tLoss: 0.000214\t训练正确率: 99.65%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 84 [0/30596 (0%)]\tLoss: 0.058522\t训练正确率: 98.44%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 84 [6400/30596 (21%)]\tLoss: 0.013584\t训练正确率: 99.58%\t校验正确率: 99.69%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 84 [12800/30596 (42%)]\tLoss: 0.001634\t训练正确率: 99.60%\t校验正确率: 99.61%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 84 [19200/30596 (63%)]\tLoss: 0.036838\t训练正确率: 99.60%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 84 [25600/30596 (84%)]\tLoss: 0.027476\t训练正确率: 99.58%\t校验正确率: 99.65%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 85 [0/30596 (0%)]\tLoss: 0.001421\t训练正确率: 100.00%\t校验正确率: 99.77%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 85 [6400/30596 (21%)]\tLoss: 0.000388\t训练正确率: 99.68%\t校验正确率: 99.77%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 85 [12800/30596 (42%)]\tLoss: 0.010110\t训练正确率: 99.63%\t校验正确率: 99.73%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 85 [19200/30596 (63%)]\tLoss: 0.014579\t训练正确率: 99.68%\t校验正确率: 99.77%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 85 [25600/30596 (84%)]\tLoss: 0.004004\t训练正确率: 99.70%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 86 [0/30596 (0%)]\tLoss: 0.001786\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 86 [6400/30596 (21%)]\tLoss: 0.004811\t训练正确率: 99.72%\t校验正确率: 99.65%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 86 [12800/30596 (42%)]\tLoss: 0.002368\t训练正确率: 99.75%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 86 [19200/30596 (63%)]\tLoss: 0.011086\t训练正确率: 99.75%\t校验正确率: 99.73%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 86 [25600/30596 (84%)]\tLoss: 0.004255\t训练正确率: 99.75%\t校验正确率: 99.81%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 87 [0/30596 (0%)]\tLoss: 0.000632\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 87 [6400/30596 (21%)]\tLoss: 0.000856\t训练正确率: 99.69%\t校验正确率: 99.77%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 87 [12800/30596 (42%)]\tLoss: 0.003627\t训练正确率: 99.72%\t校验正确率: 99.65%\n",
      "(tensor(2565), 2569)\n",
      "训练周期: 87 [19200/30596 (63%)]\tLoss: 0.006597\t训练正确率: 99.74%\t校验正确率: 99.84%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 87 [25600/30596 (84%)]\tLoss: 0.011534\t训练正确率: 99.74%\t校验正确率: 99.65%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 88 [0/30596 (0%)]\tLoss: 0.000317\t训练正确率: 100.00%\t校验正确率: 99.73%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 88 [6400/30596 (21%)]\tLoss: 0.000460\t训练正确率: 99.77%\t校验正确率: 99.69%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 88 [12800/30596 (42%)]\tLoss: 0.006235\t训练正确率: 99.79%\t校验正确率: 99.81%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 88 [19200/30596 (63%)]\tLoss: 0.004750\t训练正确率: 99.80%\t校验正确率: 99.77%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 88 [25600/30596 (84%)]\tLoss: 0.001420\t训练正确率: 99.80%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 89 [0/30596 (0%)]\tLoss: 0.000650\t训练正确率: 100.00%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 89 [6400/30596 (21%)]\tLoss: 0.006013\t训练正确率: 99.85%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 89 [12800/30596 (42%)]\tLoss: 0.000724\t训练正确率: 99.79%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 89 [19200/30596 (63%)]\tLoss: 0.007540\t训练正确率: 99.78%\t校验正确率: 99.69%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 89 [25600/30596 (84%)]\tLoss: 0.001327\t训练正确率: 99.77%\t校验正确率: 99.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2563), 2569)\n",
      "训练周期: 90 [0/30596 (0%)]\tLoss: 0.000351\t训练正确率: 100.00%\t校验正确率: 99.77%\n",
      "(tensor(2557), 2569)\n",
      "训练周期: 90 [6400/30596 (21%)]\tLoss: 0.001586\t训练正确率: 99.72%\t校验正确率: 99.53%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 90 [12800/30596 (42%)]\tLoss: 0.013936\t训练正确率: 99.76%\t校验正确率: 99.77%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 90 [19200/30596 (63%)]\tLoss: 0.000041\t训练正确率: 99.71%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 90 [25600/30596 (84%)]\tLoss: 0.000697\t训练正确率: 99.70%\t校验正确率: 99.65%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 91 [0/30596 (0%)]\tLoss: 0.001016\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 91 [6400/30596 (21%)]\tLoss: 0.000890\t训练正确率: 99.68%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 91 [12800/30596 (42%)]\tLoss: 0.000411\t训练正确率: 99.70%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 91 [19200/30596 (63%)]\tLoss: 0.000795\t训练正确率: 99.67%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 91 [25600/30596 (84%)]\tLoss: 0.000185\t训练正确率: 99.68%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 92 [0/30596 (0%)]\tLoss: 0.004966\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 92 [6400/30596 (21%)]\tLoss: 0.003397\t训练正确率: 99.74%\t校验正确率: 99.69%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 92 [12800/30596 (42%)]\tLoss: 0.017951\t训练正确率: 99.73%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 92 [19200/30596 (63%)]\tLoss: 0.000579\t训练正确率: 99.69%\t校验正确率: 99.73%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 92 [25600/30596 (84%)]\tLoss: 0.004606\t训练正确率: 99.70%\t校验正确率: 99.73%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 93 [0/30596 (0%)]\tLoss: 0.018074\t训练正确率: 100.00%\t校验正确率: 99.57%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 93 [6400/30596 (21%)]\tLoss: 0.000075\t训练正确率: 99.85%\t校验正确率: 99.73%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 93 [12800/30596 (42%)]\tLoss: 0.005198\t训练正确率: 99.81%\t校验正确率: 99.77%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 93 [19200/30596 (63%)]\tLoss: 0.000599\t训练正确率: 99.76%\t校验正确率: 99.69%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 93 [25600/30596 (84%)]\tLoss: 0.002083\t训练正确率: 99.73%\t校验正确率: 99.77%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 94 [0/30596 (0%)]\tLoss: 0.006568\t训练正确率: 100.00%\t校验正确率: 99.81%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 94 [6400/30596 (21%)]\tLoss: 0.000235\t训练正确率: 99.81%\t校验正确率: 99.65%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 94 [12800/30596 (42%)]\tLoss: 0.005546\t训练正确率: 99.81%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 94 [19200/30596 (63%)]\tLoss: 0.006937\t训练正确率: 99.80%\t校验正确率: 99.65%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 94 [25600/30596 (84%)]\tLoss: 0.001325\t训练正确率: 99.78%\t校验正确率: 99.65%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 95 [0/30596 (0%)]\tLoss: 0.028653\t训练正确率: 98.44%\t校验正确率: 99.73%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 95 [6400/30596 (21%)]\tLoss: 0.000178\t训练正确率: 99.71%\t校验正确率: 99.61%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 95 [12800/30596 (42%)]\tLoss: 0.003944\t训练正确率: 99.72%\t校验正确率: 99.65%\n",
      "(tensor(2562), 2569)\n",
      "训练周期: 95 [19200/30596 (63%)]\tLoss: 0.001473\t训练正确率: 99.71%\t校验正确率: 99.73%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 95 [25600/30596 (84%)]\tLoss: 0.014386\t训练正确率: 99.70%\t校验正确率: 99.65%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 96 [0/30596 (0%)]\tLoss: 0.001645\t训练正确率: 100.00%\t校验正确率: 99.77%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 96 [6400/30596 (21%)]\tLoss: 0.031973\t训练正确率: 99.60%\t校验正确率: 99.61%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 96 [12800/30596 (42%)]\tLoss: 0.007084\t训练正确率: 99.67%\t校验正确率: 99.61%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 96 [19200/30596 (63%)]\tLoss: 0.001022\t训练正确率: 99.69%\t校验正确率: 99.69%\n",
      "(tensor(2559), 2569)\n",
      "训练周期: 96 [25600/30596 (84%)]\tLoss: 0.049830\t训练正确率: 99.71%\t校验正确率: 99.61%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 97 [0/30596 (0%)]\tLoss: 0.002721\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 97 [6400/30596 (21%)]\tLoss: 0.000316\t训练正确率: 99.75%\t校验正确率: 99.65%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 97 [12800/30596 (42%)]\tLoss: 0.001102\t训练正确率: 99.75%\t校验正确率: 99.77%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 97 [19200/30596 (63%)]\tLoss: 0.002871\t训练正确率: 99.77%\t校验正确率: 99.65%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 97 [25600/30596 (84%)]\tLoss: 0.003496\t训练正确率: 99.78%\t校验正确率: 99.81%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 98 [0/30596 (0%)]\tLoss: 0.002483\t训练正确率: 100.00%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 98 [6400/30596 (21%)]\tLoss: 0.000767\t训练正确率: 99.83%\t校验正确率: 99.65%\n",
      "(tensor(2558), 2569)\n",
      "训练周期: 98 [12800/30596 (42%)]\tLoss: 0.006959\t训练正确率: 99.81%\t校验正确率: 99.57%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 98 [19200/30596 (63%)]\tLoss: 0.032733\t训练正确率: 99.75%\t校验正确率: 99.69%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 98 [25600/30596 (84%)]\tLoss: 0.002946\t训练正确率: 99.76%\t校验正确率: 99.65%\n",
      "(tensor(2563), 2569)\n",
      "训练周期: 99 [0/30596 (0%)]\tLoss: 0.000918\t训练正确率: 100.00%\t校验正确率: 99.77%\n",
      "(tensor(2560), 2569)\n",
      "训练周期: 99 [6400/30596 (21%)]\tLoss: 0.002490\t训练正确率: 99.74%\t校验正确率: 99.65%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 99 [12800/30596 (42%)]\tLoss: 0.049986\t训练正确率: 99.74%\t校验正确率: 99.81%\n",
      "(tensor(2564), 2569)\n",
      "训练周期: 99 [19200/30596 (63%)]\tLoss: 0.004938\t训练正确率: 99.72%\t校验正确率: 99.81%\n",
      "(tensor(2561), 2569)\n",
      "训练周期: 99 [25600/30596 (84%)]\tLoss: 0.002133\t训练正确率: 99.74%\t校验正确率: 99.69%\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet() #新建一个卷积神经网络的实例，此时ConvNet的__init__函数就会被自动调用\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #Loss函数的定义，交叉熵\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #定义优化器，普通的随机梯度下降算法\n",
    "\n",
    "record = [] #记录准确率等数值的容器\n",
    "weights = [] #每若干步就记录一次卷积核\n",
    "\n",
    "#开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_rights = [] #记录训练数据集准确率的容器\n",
    "    \n",
    "    ''' 下面的enumerate是构造一个枚举器的作用。就是我们在对train_loader做循环迭代的时候，enumerate会自动吐出一个数字指示我们循环了几次\n",
    "     这个数字就被记录在了batch_idx之中，它就等于0，1，2，……\n",
    "     train_loader每迭代一次，就会吐出来一对数据data和target，分别对应着一个batch中的手写数字图，以及对应的标签。'''\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  #针对容器中的每一个批进行循环\n",
    "        data, target = data.clone().requires_grad_(True), target.clone().detach()  #data为一批图像，target为一批标签\n",
    "        net.train() # 给网络模型做标记，标志说模型正在训练集上训练，\n",
    "                    #这种区分主要是为了打开关闭net的training标志，从而决定是否运行dropout\n",
    "            \n",
    "        output = net(data) #神经网络完成一次前馈的计算过程，得到预测输出output\n",
    "        loss = criterion(output, target) #将output与标签target比较，计算误差\n",
    "        optimizer.zero_grad() #清空梯度\n",
    "        loss.backward() #反向传播\n",
    "        optimizer.step() #一步随机梯度下降算法\n",
    "        right = rightness(output, target) #计算准确率所需数值，返回数值为（正确样例数，总样本数）\n",
    "        train_rights.append(right) #将计算结果装到列表容器train_rights中\n",
    "\n",
    "    \n",
    "        if batch_idx % 100 == 0: #每间隔100个batch执行一次打印等操作\n",
    "            \n",
    "            net.eval() # 给网络模型做标记，标志说模型在训练集上训练\n",
    "            val_rights = [] #记录校验数据集准确率的容器\n",
    "            \n",
    "            '''开始在校验数据集上做循环，计算校验集上面的准确度'''\n",
    "            for (data, target) in validation_loader:\n",
    "                data, target = data.clone().requires_grad_(True), target.clone().detach()\n",
    "                output = net(data) #完成一次前馈计算过程，得到目前训练得到的模型net在校验数据集上的表现\n",
    "                right = rightness(output, target) #计算准确率所需数值，返回正确的数值为（正确样例数，总样本数）\n",
    "                val_rights.append(right)\n",
    "            \n",
    "            # 分别计算在目前已经计算过的测试数据集，以及全部校验集上模型的表现：分类准确率\n",
    "            #train_r为一个二元组，分别记录目前已经经历过的所有训练集中分类正确的数量和该集合中总的样本数，\n",
    "            #train_r[0]/train_r[1]就是训练集的分类准确度，同样，val_r[0]/val_r[1]就是校验集上的分类准确度\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            #val_r为一个二元组，分别记录校验集中分类正确的数量和该集合中总的样本数\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "            #打印准确率等数值，其中正确率为本训练周期Epoch开始后到目前撮的正确率的平均值\n",
    "            print(val_r)\n",
    "            print('训练周期: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t训练正确率: {:.2f}%\\t校验正确率: {:.2f}%'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.data, \n",
    "                100. * train_r[0].numpy() / train_r[1], \n",
    "                100. * val_r[0].numpy() / val_r[1]))\n",
    "            \n",
    "            #将准确率和权重等数值加载到容器中，以方便后续处理\n",
    "            record.append((100 - 100. * train_r[0] / train_r[1], 100 - 100. * val_r[0] / val_r[1]))\n",
    "            \n",
    "            # weights记录了训练周期中所有卷积核的演化过程。net.conv1.weight就提取出了第一层卷积核的权重\n",
    "            # clone的意思就是将weight.data中的数据做一个拷贝放到列表中，否则当weight.data变化的时候，列表中的每一项数值也会联动\n",
    "            '''这里使用clone这个函数很重要'''\n",
    "            weights.append([net.conv1.weight.data.clone(), net.conv1.bias.data.clone(), \n",
    "                            net.conv2.weight.data.clone(), net.conv2.bias.data.clone()])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制训练过程的误差曲线，校验集和测试集上的错误率。\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot(record) #record记载了每一个打印周期记录的训练和校验数据集上的准确度\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Error rate')\n",
    "plt.savefig('minst_conv_0-4.jpg', dpi=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里保存已经训练好的神经网络\n",
    "torch.save(net, 'minst_conv_0-4_checkpoint') #后面的字符串为保存文件的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
